{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data partitioning\n",
    "\n",
    "In this notebook we will take the conditioned data that we have, the data should be in the form of a two collumn csv that has the block numvber on the left and the MEV quantity sorted in to none = 0, low = 1, medium = 2, and high =3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from numba import jit\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../Ethdata/randomdata.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/sufyansaleem/mevhackathon/MEVHackathon/DataPrep/datapartitioning.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sufyansaleem/mevhackathon/MEVHackathon/DataPrep/datapartitioning.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#let pull the data in and so that we can check how big the files are. \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sufyansaleem/mevhackathon/MEVHackathon/DataPrep/datapartitioning.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m my_data \u001b[39m=\u001b[39m genfromtxt(\u001b[39m'\u001b[39;49m\u001b[39m../Ethdata/randomdata.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sufyansaleem/mevhackathon/MEVHackathon/DataPrep/datapartitioning.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(my_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sufyansaleem/mevhackathon/MEVHackathon/DataPrep/datapartitioning.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mshape(my_data))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py:1793\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   1791\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1792\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1793\u001b[0m     fid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m   1794\u001b[0m     fid_ctx \u001b[39m=\u001b[39m contextlib\u001b[39m.\u001b[39mclosing(fid)\n\u001b[1;32m   1795\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m path)\n",
      "\u001b[0;31mOSError\u001b[0m: ../Ethdata/randomdata.csv not found."
     ]
    }
   ],
   "source": [
    "#let pull the data in and so that we can check how big the files are. \n",
    "\n",
    "my_data = genfromtxt('../Ethdata/randomdata.csv', delimiter=',')\n",
    "print(my_data)\n",
    "print(np.shape(my_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 1. 3.]\n",
      " [1. 3. 0.]\n",
      " [3. 0. 1.]\n",
      " ...\n",
      " [1. 3. 3.]\n",
      " [3. 3. 0.]\n",
      " [3. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datalets = np.zeros((np.shape(my_data)[0],3))\n",
    "\n",
    "datalets[:,0] = my_data[:,1]\n",
    "\n",
    "my_data2 = np.delete(my_data[:,1],0,0)\n",
    "\n",
    "my_data2 = np.append(my_data2,[0])\n",
    "\n",
    "datalets[:,1] = my_data2\n",
    "\n",
    "my_data3 = np.delete(my_data[:,1],[0,1],0)\n",
    "\n",
    "my_data3 = np.append(my_data3,[0,0])\n",
    "\n",
    "datalets[:,2] = my_data3\n",
    "\n",
    "#lastly we need to delete the last three rows, as I had to just input zeros there to to that the array didn't have any missing point,\n",
    "\n",
    "datalets = np.delete(datalets,[-1,-2,-3],0)\n",
    "\n",
    "print(datalets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datalet2': array([[3, 1],\n",
      "       [1, 3],\n",
      "       [3, 0],\n",
      "       ...,\n",
      "       [3, 3],\n",
      "       [3, 0],\n",
      "       [0, 0]]), 'datalet3': array([[3, 1, 3],\n",
      "       [1, 3, 0],\n",
      "       [3, 0, 1],\n",
      "       ...,\n",
      "       [1, 3, 3],\n",
      "       [3, 3, 0],\n",
      "       [3, 0, 0]]), 'datalet4': array([[3, 1, 3, 0],\n",
      "       [1, 3, 0, 1],\n",
      "       [3, 0, 1, 0],\n",
      "       ...,\n",
      "       [3, 1, 3, 3],\n",
      "       [1, 3, 3, 0],\n",
      "       [3, 3, 0, 0]]), 'datalet5': array([[3, 1, 3, 0, 1],\n",
      "       [1, 3, 0, 1, 0],\n",
      "       [3, 0, 1, 0, 0],\n",
      "       ...,\n",
      "       [0, 3, 1, 3, 3],\n",
      "       [3, 1, 3, 3, 0],\n",
      "       [1, 3, 3, 0, 0]]), 'datalet6': array([[3, 1, 3, 0, 1, 0],\n",
      "       [1, 3, 0, 1, 0, 0],\n",
      "       [3, 0, 1, 0, 0, 1],\n",
      "       ...,\n",
      "       [1, 0, 3, 1, 3, 3],\n",
      "       [0, 3, 1, 3, 3, 0],\n",
      "       [3, 1, 3, 3, 0, 0]]), 'datalet7': array([[3, 1, 3, ..., 1, 0, 0],\n",
      "       [1, 3, 0, ..., 0, 0, 1],\n",
      "       [3, 0, 1, ..., 0, 1, 1],\n",
      "       ...,\n",
      "       [0, 1, 0, ..., 1, 3, 3],\n",
      "       [1, 0, 3, ..., 3, 3, 0],\n",
      "       [0, 3, 1, ..., 3, 0, 0]]), 'datalet8': array([[3, 1, 3, ..., 0, 0, 1],\n",
      "       [1, 3, 0, ..., 0, 1, 1],\n",
      "       [3, 0, 1, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [0, 0, 1, ..., 1, 3, 3],\n",
      "       [0, 1, 0, ..., 3, 3, 0],\n",
      "       [1, 0, 3, ..., 3, 0, 0]]), 'datalet9': array([[3, 1, 3, ..., 0, 1, 1],\n",
      "       [1, 3, 0, ..., 1, 1, 1],\n",
      "       [3, 0, 1, ..., 1, 1, 3],\n",
      "       ...,\n",
      "       [2, 0, 0, ..., 1, 3, 3],\n",
      "       [0, 0, 1, ..., 3, 3, 0],\n",
      "       [0, 1, 0, ..., 3, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "#what this function will do is take one data point and the next two after, the next one after will be used with that one for the x part of the data and the third will be the y position, \n",
    "#the answer that we are asking here is can you predict the next MEV quantity based on the two before. This might look a little arduous, however doing it this way all in np, is much \n",
    "#much mich faster than trying to do it any other way, a for loop over 10000000 data entries would just take way too long. \n",
    "\n",
    "\n",
    "#this parameter will set what the maximum datalet length will be i.e. how many blocks back we want to go to predict the MEV level of the next block\n",
    "\n",
    "n = 9\n",
    "\n",
    "#start by making a dictionary to hold all this data\n",
    "\n",
    "datalets = {}\n",
    "\n",
    "# Then we loop over, the default is set from 2-10, this is the length of hte data length, the x vector will be one less than this. \n",
    "\n",
    "for i in range(2,n+1):\n",
    "    \n",
    "    # Start with an all zeros np array so we can get started, it will have i columns because that is the number of \n",
    "    \n",
    "    datalet = np.zeros((np.shape(my_data)[0],i))\n",
    "    \n",
    "    #this will clone the price column, delete the top entry to shift it all down, put some nonsense in at the bottom then add it to the datalets dictionary.\n",
    "    \n",
    "    for j in range(i):\n",
    "        data = np.delete(my_data[:,1],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(int)\n",
    "        datalet[:,j] = data\n",
    "        \n",
    "    # to not screw up the results this next couple of lines get rid of the nonsence that we added in the bottom rows. \n",
    "        \n",
    "    datalet = datalet.astype(int)\n",
    "    datalet = np.delete(datalet,range(i*(-1),0),0)\n",
    "        \n",
    "    datalets[\"datalet{}\".format(i)] = datalet\n",
    "\n",
    "print(datalets)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these datalets as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in datalets.items():\n",
    "    headers = []\n",
    "    for i in range(np.shape(y)[1]):\n",
    "        headers.append('period{}'.format(i))\n",
    "    headerstr = ','.join(map(str,headers))\n",
    "    np.savetxt(\"..\\datalets\\{}.csv\".format(x), y, delimiter=\",\", header= headerstr, comments = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b96cf7c584300418372ada66fd91b36326cee32dac945e6b465115698cdfa50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
