{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data partitioning\n",
    "\n",
    "In this notebook we will take the conditioned data that we have, the data should be in the form of a two column csv that has the block numvber on the left and the MEV quantity sorted in to none = 0, low = 1, medium = 2, and high =3. This notebook is specifically for the data with the gas fees and the price volatility of etherium at the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from numba import jit\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 2.000e+00 1.000e+00 0.000e+00]\n",
      " [1.000e+00 1.000e+00 2.000e+00 2.000e+00]\n",
      " [2.000e+00 3.000e+00 3.000e+00 1.000e+00]\n",
      " ...\n",
      " [9.997e+03 0.000e+00 1.000e+00 3.000e+00]\n",
      " [9.998e+03 1.000e+00 1.000e+00 3.000e+00]\n",
      " [9.999e+03 0.000e+00 3.000e+00 0.000e+00]]\n",
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "#let pull the data in and so that we can check how big the files are. \n",
    "\n",
    "my_data = genfromtxt('../Ethdata/randomdatawgv.csv', delimiter=',')\n",
    "print(my_data)\n",
    "print(np.shape(my_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datalet2': array([[2., 1., 1., 2., 0., 2.],\n",
      "       [1., 3., 2., 3., 2., 1.],\n",
      "       [3., 1., 3., 2., 1., 3.],\n",
      "       ...,\n",
      "       [0., 3., 3., 2., 1., 0.],\n",
      "       [3., 0., 2., 1., 0., 3.],\n",
      "       [0., 1., 1., 1., 3., 3.]]), 'datalet3': array([[2., 1., 3., ..., 0., 2., 1.],\n",
      "       [1., 3., 1., ..., 2., 1., 3.],\n",
      "       [3., 1., 3., ..., 1., 3., 1.],\n",
      "       ...,\n",
      "       [2., 0., 3., ..., 2., 1., 0.],\n",
      "       [0., 3., 0., ..., 1., 0., 3.],\n",
      "       [3., 0., 1., ..., 0., 3., 3.]]), 'datalet4': array([[2., 1., 3., ..., 2., 1., 3.],\n",
      "       [1., 3., 1., ..., 1., 3., 1.],\n",
      "       [3., 1., 3., ..., 3., 1., 1.],\n",
      "       ...,\n",
      "       [2., 2., 0., ..., 2., 1., 0.],\n",
      "       [2., 0., 3., ..., 1., 0., 3.],\n",
      "       [0., 3., 0., ..., 0., 3., 3.]]), 'datalet5': array([[2., 1., 3., ..., 1., 3., 1.],\n",
      "       [1., 3., 1., ..., 3., 1., 1.],\n",
      "       [3., 1., 3., ..., 1., 1., 3.],\n",
      "       ...,\n",
      "       [0., 2., 2., ..., 2., 1., 0.],\n",
      "       [2., 2., 0., ..., 1., 0., 3.],\n",
      "       [2., 0., 3., ..., 0., 3., 3.]]), 'datalet6': array([[2., 1., 3., ..., 3., 1., 1.],\n",
      "       [1., 3., 1., ..., 1., 1., 3.],\n",
      "       [3., 1., 3., ..., 1., 3., 1.],\n",
      "       ...,\n",
      "       [0., 0., 2., ..., 2., 1., 0.],\n",
      "       [0., 2., 2., ..., 1., 0., 3.],\n",
      "       [2., 2., 0., ..., 0., 3., 3.]]), 'datalet7': array([[2., 1., 3., ..., 1., 1., 3.],\n",
      "       [1., 3., 1., ..., 1., 3., 1.],\n",
      "       [3., 1., 3., ..., 3., 1., 1.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 2., 1., 0.],\n",
      "       [0., 0., 2., ..., 1., 0., 3.],\n",
      "       [0., 2., 2., ..., 0., 3., 3.]]), 'datalet8': array([[2., 1., 3., ..., 1., 3., 1.],\n",
      "       [1., 3., 1., ..., 3., 1., 1.],\n",
      "       [3., 1., 3., ..., 1., 1., 1.],\n",
      "       ...,\n",
      "       [3., 0., 0., ..., 2., 1., 0.],\n",
      "       [0., 0., 0., ..., 1., 0., 3.],\n",
      "       [0., 0., 2., ..., 0., 3., 3.]]), 'datalet9': array([[2., 1., 3., ..., 3., 1., 1.],\n",
      "       [1., 3., 1., ..., 1., 1., 1.],\n",
      "       [3., 1., 3., ..., 1., 1., 0.],\n",
      "       ...,\n",
      "       [3., 3., 0., ..., 2., 1., 0.],\n",
      "       [3., 0., 0., ..., 1., 0., 3.],\n",
      "       [0., 0., 0., ..., 0., 3., 3.]])}\n"
     ]
    }
   ],
   "source": [
    "# This cell will make what I am refering to as datalets, these are strings of n periods, infact this will create all of the strings of n periods from the data available\n",
    "# we will use these to train tha models. \n",
    "\n",
    "#start by making a dictionary to hold all this data\n",
    "\n",
    "datalets = {}\n",
    "\n",
    "# Then we loop over, the default is set from 2-10, this is the length of hte data length, the x vector will be one less than this. \n",
    "\n",
    "for i in range(2,10):\n",
    "    \n",
    "    # Start with an all zeros np array so we can get started, it will have i columns because that is the number of \n",
    "    \n",
    "    datalet = np.zeros((np.shape(my_data)[0],i*3))\n",
    "    \n",
    "    for j in range(i):\n",
    "        data = np.delete(my_data[:,1],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(int)\n",
    "        datalet[:,j] = data\n",
    "\n",
    "        data = np.delete(my_data[:,2],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(float)\n",
    "        datalet[:,i+j] = data        \n",
    "        \n",
    "        data = np.delete(my_data[:,3],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(float)\n",
    "        datalet[:,2*i+j] = data        \n",
    "               \n",
    "    datalet = datalet.astype(float)\n",
    "    datalet = np.delete(datalet,range(i*(-1),0),0)\n",
    "        \n",
    "    datalets[\"datalet{}\".format(i)] = datalet\n",
    "\n",
    "print(datalets)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these datalets as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in datalets.items():\n",
    "    headers = []\n",
    "    for i in range(int(np.shape(y)[1]/3)):\n",
    "        headers.append('Mev_period{}'.format(i))\n",
    "    for i in range(int(np.shape(y)[1]/3)):\n",
    "        headers.append('gas_fees_period{}'.format(i))\n",
    "    for i in range(int(np.shape(y)[1]/3)):\n",
    "        headers.append('price_volitility_period{}'.format(i))\n",
    "    headerstr = ','.join(map(str,headers))\n",
    "    np.savetxt(\"..\\dateletswgv\\{}.csv\".format(x), y, delimiter=\",\", header= headerstr, comments = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
