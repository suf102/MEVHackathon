{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data partitioning\n",
    "\n",
    "In this notebook we will take the conditioned data that we have, the data should be in the form of a two column csv that has the block numvber on the left and the MEV quantity sorted in to none = 0, low = 1, medium = 2, and high =3. This notebook is specifically for the data with the gas fees and the price volatility of etherium at the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from numba import jit\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[           nan            nan            nan            nan\n",
      "             nan            nan]\n",
      " [0.00000000e+00 0.00000000e+00 1.18340490e+07 4.00000000e+00\n",
      "  9.99796494e-01            nan]\n",
      " [1.00000000e+00 1.00000000e+00 1.18340500e+07 0.00000000e+00\n",
      "  9.99850057e-01            nan]\n",
      " ...\n",
      " [5.20300000e+03 5.20300000e+03 1.18392520e+07 0.00000000e+00\n",
      "  9.96924509e-01 3.14770091e+08]\n",
      " [5.20400000e+03 5.20400000e+03 1.18392530e+07 0.00000000e+00\n",
      "  9.99256346e-01 3.05603242e+08]\n",
      " [5.20500000e+03 5.20500000e+03 1.18392540e+07 0.00000000e+00\n",
      "  9.99197509e-01 2.95728027e+08]]\n",
      "(5207, 6)\n",
      "[[0.00000000e+00 9.87959922e-01 1.51566715e+07]\n",
      " [0.00000000e+00 9.87496250e-01 1.50104750e+07]\n",
      " [0.00000000e+00 9.99704350e-01 1.48502837e+07]\n",
      " ...\n",
      " [0.00000000e+00 9.96924509e-01 3.14770091e+08]\n",
      " [0.00000000e+00 9.99256346e-01 3.05603242e+08]\n",
      " [0.00000000e+00 9.99197509e-01 2.95728027e+08]]\n",
      "(5157, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#let pull the data in and so that we can check how big the files are. \n",
    "\n",
    "my_data = genfromtxt('..\\Ethdata\\MEVcategorywgv.csv', delimiter=',')\n",
    "print(my_data)\n",
    "print(np.shape(my_data))\n",
    "my_data = np.delete(my_data, 0,1) #just to get rid of the index row\n",
    "my_data = np.delete(my_data, 0,1) #just to get rid of the index row\n",
    "my_data = np.delete(my_data, 0,1) #just to get rid of the index row\n",
    "my_data = np.delete(my_data,range(0,50),0) #and the nan values at the top\n",
    "\n",
    "print(my_data)\n",
    "print(np.shape(my_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datalet2': array([[0.00000000e+00, 0.00000000e+00, 9.87959922e-01, 9.87496250e-01,\n",
      "        1.51566715e+07, 1.50104750e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 9.87496250e-01, 9.99704350e-01,\n",
      "        1.50104750e+07, 1.48502837e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 9.99704350e-01, 9.98955092e-01,\n",
      "        1.48502837e+07, 1.46756392e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 9.98571011e-01, 9.96847309e-01,\n",
      "        3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 9.96847309e-01, 9.96924509e-01,\n",
      "        3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 9.96924509e-01, 9.99256346e-01,\n",
      "        3.14770091e+08, 3.05603242e+08]]), 'datalet3': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.51566715e+07, 1.50104750e+07, 1.48502837e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.50104750e+07, 1.48502837e+07, 1.46756392e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.48502837e+07, 1.46756392e+07, 1.52972620e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]]), 'datalet4': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.50104750e+07, 1.48502837e+07, 1.46756392e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.48502837e+07, 1.46756392e+07, 1.52972620e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.46756392e+07, 1.52972620e+07, 1.58245498e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]]), 'datalet5': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.48502837e+07, 1.46756392e+07, 1.52972620e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.46756392e+07, 1.52972620e+07, 1.58245498e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.52972620e+07, 1.58245498e+07, 1.62666788e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]]), 'datalet6': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.46756392e+07, 1.52972620e+07, 1.58245498e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.52972620e+07, 1.58245498e+07, 1.62666788e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.58245498e+07, 1.62666788e+07, 1.66304424e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]]), 'datalet7': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.52972620e+07, 1.58245498e+07, 1.62666788e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.58245498e+07, 1.62666788e+07, 1.66304424e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.62666788e+07, 1.66304424e+07, 1.69208953e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]]), 'datalet8': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.58245498e+07, 1.62666788e+07, 1.66304424e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.62666788e+07, 1.66304424e+07, 1.69208953e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.66304424e+07, 1.69208953e+07, 1.71417646e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]]), 'datalet9': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.62666788e+07, 1.66304424e+07, 1.69208953e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.66304424e+07, 1.69208953e+07, 1.71417646e+07],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        1.69208953e+07, 1.71417646e+07, 1.72957162e+07],\n",
      "       ...,\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.37161249e+08, 3.31220993e+08, 3.23288838e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.31220993e+08, 3.23288838e+08, 3.14770091e+08],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        3.23288838e+08, 3.14770091e+08, 3.05603242e+08]])}\n"
     ]
    }
   ],
   "source": [
    "# This cell will make what I am refering to as datalets, these are strings of n periods, infact this will create all of the strings of n periods from the data available\n",
    "# we will use these to train tha models. \n",
    "\n",
    "#this parameter will set what the maximum datalet length will be i.e. how many blocks back we want to go to predict the MEV level of the next block\n",
    "\n",
    "startrange = 2\n",
    "\n",
    "endrange = 10\n",
    "#start by making a dictionary to hold all this data\n",
    "\n",
    "datalets = {}\n",
    "\n",
    "# Then we loop over, the default is set from 2-10, this is the length of hte data length, the x vector will be one less than this. \n",
    "\n",
    "for i in range(startrange ,endrange):\n",
    "    \n",
    "    # Start with an all zeros np array so we can get started, it will have 3i collumns as each period has three bits of data, the mev, gas fees and price volitility\n",
    "    \n",
    "    datalet = np.zeros((np.shape(my_data)[0],i*3))\n",
    "    \n",
    "    # these lines wil shift the rows up and add them as the next collumn in the datalets, it is done three times to do it for the MEV, gas fees and price volatility\n",
    "    \n",
    "    for j in range(i):\n",
    "        data = np.delete(my_data[:,0],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(int)\n",
    "        datalet[:,j] = data\n",
    "\n",
    "        data = np.delete(my_data[:,1],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(float)\n",
    "        datalet[:,i+j] = data        \n",
    "        \n",
    "        data = np.delete(my_data[:,2],range(j),0)\n",
    "        data = np.append(data,range(j))\n",
    "        data = data.astype(float)\n",
    "        datalet[:,2*i+j] = data        \n",
    "        \n",
    "    #in the process above we create some nonsense rows and this just makes sure they are removed\n",
    "               \n",
    "    datalet = datalet.astype(float)\n",
    "    datalet = np.delete(datalet,range(i*(-1),0),0)\n",
    "        \n",
    "    datalets[\"datalet{}\".format(i)] = datalet\n",
    "\n",
    "print(datalets)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these datalets as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we just need to make the column headings which is what the headers do, then save it all to a csv file. \n",
    "\n",
    "for x,y in datalets.items():\n",
    "    headers = []\n",
    "    for i in range(int(np.shape(y)[1]/3)):\n",
    "        headers.append('Mev_period{}'.format(i))\n",
    "    for i in range(int(np.shape(y)[1]/3)):\n",
    "        headers.append('gas_fees_period{}'.format(i))\n",
    "    for i in range(int(np.shape(y)[1]/3)):\n",
    "        headers.append('price_volitility_period{}'.format(i))\n",
    "    headerstr = ','.join(map(str,headers))\n",
    "    np.savetxt(\"..\\dataletswgv\\{}.csv\".format(x), y, delimiter=\",\", header= headerstr, comments = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
