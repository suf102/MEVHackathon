{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning library of choice PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for number-crunching\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Time to check that the gpu optimization is actually helping\n",
    "\n",
    "import time \n",
    "\n",
    "# Some graphing\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# use GPU\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Count the number of CPU cores available, this returns the number of threads, because most cpus have a thread count equal to twice their core count I have halved the count when multithreading\n",
    "# Set this number to one if you dont want to multi thread the process\n",
    "\n",
    "cpuCount = os.cpu_count()\n",
    "print(cpuCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This value will allow you to change how many periods back the data will consider. for example if you select 1 it will only look at the previous period, Maximum value is currently set to 8.\n",
    "#if you want to try over more data periods a greater number of datalet length will need to be prepped in the data prep folders. By default a maximum of 8\n",
    "\n",
    "dataperiods = 9\n",
    "\n",
    "df = pd.read_csv('../datalets/datalet{}.csv'.format(dataperiods),index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period0</th>\n",
       "      <th>period1</th>\n",
       "      <th>period2</th>\n",
       "      <th>period3</th>\n",
       "      <th>period4</th>\n",
       "      <th>period5</th>\n",
       "      <th>period6</th>\n",
       "      <th>period7</th>\n",
       "      <th>period8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152893</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152894</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152895</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152896</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3152898 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         period0  period1  period2  period3  period4  period5  period6  \\\n",
       "0            4.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4            0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "3152893      0.0      3.0      4.0      4.0      0.0      0.0      4.0   \n",
       "3152894      3.0      4.0      4.0      0.0      0.0      4.0      4.0   \n",
       "3152895      4.0      4.0      0.0      0.0      4.0      4.0      0.0   \n",
       "3152896      4.0      0.0      0.0      4.0      4.0      0.0      0.0   \n",
       "3152897      0.0      0.0      4.0      4.0      0.0      0.0      4.0   \n",
       "\n",
       "         period7  period8  \n",
       "0            0.0      0.0  \n",
       "1            0.0      0.0  \n",
       "2            0.0      0.0  \n",
       "3            0.0      0.0  \n",
       "4            0.0      0.0  \n",
       "...          ...      ...  \n",
       "3152893      4.0      0.0  \n",
       "3152894      0.0      0.0  \n",
       "3152895      0.0      4.0  \n",
       "3152896      4.0      0.0  \n",
       "3152897      0.0      4.0  \n",
       "\n",
       "[3152898 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3152898, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataheaders = []\n",
    "\n",
    "for i in range(df.shape[1]-1):\n",
    "\tdataheaders.append('period{}'.format(i))\n",
    " \n",
    "\n",
    "\n",
    "data = torch.Tensor(df[dataheaders].values).type(torch.float)\n",
    "labels = torch.Tensor(df['period{}'.format(df.shape[1]-1)].values).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [4., 4., 0.,  ..., 4., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 4.],\n",
      "        [0., 0., 4.,  ..., 0., 4., 0.]])\n",
      "tensor([0, 0, 0,  ..., 4, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to split the data into three parts, evaluation, test and training data. I do this with two instances of train_test_split, just for the sake of convinience.\n",
    "\n",
    "traintemp_data,eval_data, traintemp_labels,eval_labels = train_test_split(data, labels, test_size=.01)\n",
    "\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(traintemp_data, traintemp_labels, test_size=.01)\n",
    "\n",
    "#then we are going to pass the data to the Pytorch data loader, this is going to allow us to split it into mini batches that will be run through the model.\n",
    "\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "train_data = train_data\n",
    "test_data = test_data\n",
    "\n",
    "#Best to keep batches to powers of two for speed reasons adjust as needed for your own memory constraints \n",
    "x = 15\n",
    "batches   = 2**x\n",
    "train_loader = DataLoader(train_data,batch_size=batches,shuffle=True,drop_last=True, num_workers=int(cpuCount/2))\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "\n",
    "class ANN(nn.Module):\n",
    "\tdef __init__(self, Input_dim, Output_dim):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t### input layer\n",
    "\t\tself.input = nn.Linear(Input_dim,4)\n",
    "\t\t\n",
    "\t\t### hidden layers\n",
    "\t\tself.hidden1    = nn.Linear(4,4)\n",
    "\t\tself.bnorm1 = nn.BatchNorm1d(4) \n",
    "\t\tself.hidden2    = nn.Linear(4,4)\n",
    "\t\tself.bnorm2 = nn.BatchNorm1d(4) \n",
    "\t\tself.hidden3    = nn.Linear(4,4)\n",
    "\t\tself.bnorm3 = nn.BatchNorm1d(4)\n",
    "\t\tself.hidden4    = nn.Linear(4,4)\n",
    "\n",
    "\t\t### output layer\n",
    "\t\tself.output = nn.Linear(4,Output_dim)\n",
    "\t\n",
    "\t# forward pass\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\t# input (x starts off normalized)\n",
    "\t\tx = F.relu( self.input(x) )\n",
    "\n",
    "\n",
    "\t\t# hidden layer 1\n",
    "\t\tx = self.bnorm1(x) # batchnorm\n",
    "\t\tx = F.relu( self.hidden1(x) )      # linear function and activation function\n",
    "\n",
    "\t\t# hidden layer 2\n",
    "\t\tx = self.bnorm2(x) # batchnorm\n",
    "\t\tx = F.relu( self.hidden2(x) )      # linear function and activation function\n",
    "\t\t\n",
    "\t\t# hidden layer 3\n",
    "\t\tx = self.bnorm3(x)\n",
    "\t\tx = F.relu( self.hidden3(x) )      # linear function and activation function\n",
    "  \n",
    "\t\t# hidden layer 4\n",
    "\n",
    "\t\tx = F.relu( self.hidden4(x) )\n",
    "\n",
    "\t\t# output layer\n",
    "\t\treturn self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainthemodel(learning):\n",
    "\t\n",
    "\t# Loss function and optimizer, I chose cross entropy loss as it is best for classification problems. \n",
    "\tlossfun = nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.SGD(model.parameters(),lr=learning)\n",
    "\t\n",
    "\t#initialize losses\n",
    "\tlosses = torch.zeros(numofepochs)\n",
    "\ttrainAcc = []\n",
    "\ttestAcc = []\n",
    "\n",
    "\tmodel.to(device)\n",
    "\t\n",
    "\t#now lets actually loop over the training epochs to train the model\n",
    "\tfor epoch in range(numofepochs):\n",
    "\t\t\n",
    "\t\t# switch on training mode\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\t# loop over training data batches\n",
    "\t\tbatchAcc  = []\n",
    "\t\tbatchLoss = []\n",
    "\t\tfor X,y in train_loader:\n",
    "\n",
    "\t\t\tX = X.to(device)\n",
    "\t\t\ty = y.to(device)\n",
    "\t\t\t\n",
    "\t\t\t# forward pass and loss\n",
    "\t\t\tyHat = model(X)\n",
    "\t\t\tloss = lossfun(yHat,y)\n",
    "\n",
    "\t\t\t# backprop\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# loss from this batch\n",
    "\t\t\tbatchLoss.append(loss.item())\n",
    "\n",
    "\t\t\tyHat = yHat.cpu()\n",
    "\t\t\ty = y.cpu()\n",
    "\n",
    "\t\t\t# compute training accuracy for this batch\n",
    "\t\t\tbatchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "\t\t\t\n",
    "\t\t# now that we've trained through the batches, get their average training accuracy\n",
    "\t\ttrainAcc.append( np.mean(batchAcc)) \n",
    "\n",
    "\t\t# and get average losses across the batches\n",
    "\t\tlosses[epoch] = np.mean(batchLoss)\n",
    "\t\t\n",
    "\t\t### test accuracy\n",
    "\n",
    "\t\t# Lets turn eval back on so we dont overfit with the test data \n",
    "\t\tmodel.eval()\n",
    "\t\tX,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "\n",
    "\t\tX = X.to(device)\n",
    "\t\ty = y.to(device)  \n",
    "\n",
    "\t\twith torch.no_grad(): # deactivates autograd\n",
    "\t\t\tyHat = model(X)\n",
    "   \n",
    "\t\tyHat = yHat.cpu()\n",
    "\t\ty = y.cpu()   \n",
    "\n",
    "\t\ttestAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()) )\n",
    "\n",
    "\t\tprint('epoch {} done at time {} '.format(epoch,time.perf_counter()))\n",
    "\n",
    "\n",
    "\t# function output\n",
    "\treturn trainAcc,testAcc,losses,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 done at time 20.4141199 \n",
      "epoch 1 done at time 28.8714335 \n",
      "epoch 2 done at time 37.542937 \n",
      "epoch 3 done at time 45.5422836 \n",
      "epoch 4 done at time 53.9838926 \n",
      "epoch 5 done at time 62.50293 \n",
      "epoch 6 done at time 70.9602571 \n",
      "epoch 7 done at time 80.3266671 \n",
      "epoch 8 done at time 90.3502481 \n",
      "epoch 9 done at time 99.2468452 \n",
      "epoch 10 done at time 107.6353844 \n",
      "epoch 11 done at time 116.3607322 \n",
      "epoch 12 done at time 125.3617378 \n",
      "epoch 13 done at time 134.1203828 \n",
      "epoch 14 done at time 142.8983275 \n",
      "epoch 15 done at time 151.6567004 \n",
      "epoch 16 done at time 160.1617343 \n",
      "epoch 17 done at time 168.7422036 \n",
      "epoch 18 done at time 177.8726767 \n",
      "epoch 19 done at time 186.4574109 \n",
      "epoch 20 done at time 195.5454592 \n",
      "epoch 21 done at time 204.3161502 \n",
      "epoch 22 done at time 212.7264351 \n",
      "epoch 23 done at time 221.6016731 \n",
      "epoch 24 done at time 230.5030893 \n",
      "epoch 25 done at time 239.0629439 \n",
      "epoch 26 done at time 248.0275483 \n",
      "epoch 27 done at time 256.6265032 \n",
      "epoch 28 done at time 265.5421968 \n",
      "epoch 29 done at time 274.0788539 \n",
      "epoch 30 done at time 283.0409361 \n",
      "epoch 31 done at time 291.980651 \n",
      "epoch 32 done at time 300.9751419 \n",
      "epoch 33 done at time 309.8882455 \n",
      "epoch 34 done at time 318.8155751 \n",
      "epoch 35 done at time 327.4440846 \n",
      "epoch 36 done at time 335.9912863 \n",
      "epoch 37 done at time 344.2747509 \n",
      "epoch 38 done at time 353.0306517 \n",
      "epoch 39 done at time 361.8804877 \n",
      "epoch 40 done at time 370.4353264 \n",
      "epoch 41 done at time 379.4003415 \n",
      "epoch 42 done at time 388.2844055 \n",
      "epoch 43 done at time 397.0182079 \n",
      "epoch 44 done at time 406.3196737 \n",
      "epoch 45 done at time 414.8234539 \n",
      "epoch 46 done at time 423.65381 \n",
      "epoch 47 done at time 432.350014 \n",
      "epoch 48 done at time 441.1539942 \n",
      "epoch 49 done at time 450.3570069 \n",
      "epoch 50 done at time 459.3390981 \n",
      "epoch 51 done at time 467.9183765 \n",
      "epoch 52 done at time 476.7075739 \n",
      "epoch 53 done at time 485.5525351 \n",
      "epoch 54 done at time 493.9653539 \n",
      "epoch 55 done at time 502.6019487 \n",
      "epoch 56 done at time 511.5902593 \n",
      "epoch 57 done at time 520.4734984 \n",
      "epoch 58 done at time 529.356117 \n",
      "epoch 59 done at time 538.178459 \n",
      "epoch 60 done at time 546.9733905 \n",
      "epoch 61 done at time 555.455296 \n",
      "epoch 62 done at time 563.7129923 \n",
      "epoch 63 done at time 572.4692385 \n",
      "epoch 64 done at time 581.0630032 \n",
      "epoch 65 done at time 590.1748335 \n",
      "epoch 66 done at time 599.3931378 \n",
      "epoch 67 done at time 608.8128784 \n",
      "epoch 68 done at time 617.7528288 \n",
      "epoch 69 done at time 626.9076887 \n",
      "epoch 70 done at time 635.5041608 \n",
      "epoch 71 done at time 644.6110293 \n",
      "epoch 72 done at time 653.3684217 \n",
      "epoch 73 done at time 661.8430305 \n",
      "epoch 74 done at time 670.7400164 \n",
      "epoch 75 done at time 679.3655396 \n",
      "epoch 76 done at time 688.1399168 \n",
      "epoch 77 done at time 696.2528472 \n",
      "epoch 78 done at time 705.0124324 \n",
      "epoch 79 done at time 713.5891376 \n",
      "epoch 80 done at time 721.9590715 \n",
      "epoch 81 done at time 730.4877921 \n",
      "epoch 82 done at time 738.8699684 \n",
      "epoch 83 done at time 747.4204887 \n",
      "epoch 84 done at time 755.6457607 \n",
      "epoch 85 done at time 764.259235 \n",
      "epoch 86 done at time 772.7143133 \n",
      "epoch 87 done at time 781.0835807 \n",
      "epoch 88 done at time 789.81093 \n",
      "epoch 89 done at time 798.4774297 \n",
      "epoch 90 done at time 806.8153218 \n",
      "epoch 91 done at time 815.7029279 \n",
      "epoch 92 done at time 824.1268965 \n",
      "epoch 93 done at time 832.4787438 \n",
      "epoch 94 done at time 840.9155827 \n",
      "epoch 95 done at time 849.4836393 \n",
      "epoch 96 done at time 857.8463784 \n",
      "epoch 97 done at time 866.0463185 \n",
      "epoch 98 done at time 874.2410799 \n",
      "epoch 99 done at time 882.9260643 \n",
      "epoch 100 done at time 891.2180562 \n",
      "epoch 101 done at time 899.6587746 \n",
      "epoch 102 done at time 907.6951258 \n",
      "epoch 103 done at time 916.216694 \n",
      "epoch 104 done at time 924.4530316 \n",
      "epoch 105 done at time 932.7209005 \n",
      "epoch 106 done at time 941.2513482 \n",
      "epoch 107 done at time 949.9391769 \n",
      "epoch 108 done at time 958.6446073 \n",
      "epoch 109 done at time 967.0951369 \n",
      "epoch 110 done at time 975.640665 \n",
      "epoch 111 done at time 984.05057 \n",
      "epoch 112 done at time 992.4167693 \n",
      "epoch 113 done at time 1001.0350348 \n",
      "epoch 114 done at time 1009.9912569 \n",
      "epoch 115 done at time 1018.3526495 \n",
      "epoch 116 done at time 1026.4823425 \n",
      "epoch 117 done at time 1034.7100299 \n",
      "epoch 118 done at time 1043.0457288 \n",
      "epoch 119 done at time 1051.3632898 \n",
      "epoch 120 done at time 1059.6918418 \n",
      "epoch 121 done at time 1068.2710883 \n",
      "epoch 122 done at time 1076.7282926 \n",
      "epoch 123 done at time 1085.0083044 \n",
      "epoch 124 done at time 1093.6806734 \n",
      "epoch 125 done at time 1102.1558543 \n",
      "epoch 126 done at time 1110.3113935 \n",
      "epoch 127 done at time 1118.3199279 \n",
      "epoch 128 done at time 1126.3784572 \n",
      "epoch 129 done at time 1134.7427996 \n",
      "epoch 130 done at time 1143.1397013 \n",
      "epoch 131 done at time 1151.2821622 \n",
      "epoch 132 done at time 1159.9628452 \n",
      "epoch 133 done at time 1168.2789557 \n",
      "epoch 134 done at time 1176.4721639 \n",
      "epoch 135 done at time 1184.8560972 \n",
      "epoch 136 done at time 1193.3576251 \n",
      "epoch 137 done at time 1201.7300874 \n",
      "epoch 138 done at time 1210.500072 \n",
      "epoch 139 done at time 1219.6191254 \n",
      "epoch 140 done at time 1228.311799 \n",
      "epoch 141 done at time 1236.386785 \n",
      "epoch 142 done at time 1244.9470605 \n",
      "epoch 143 done at time 1253.2855924 \n",
      "epoch 144 done at time 1261.4739662 \n",
      "epoch 145 done at time 1269.8893974 \n",
      "epoch 146 done at time 1278.2882995 \n",
      "epoch 147 done at time 1287.8428568 \n",
      "epoch 148 done at time 1296.2879387 \n",
      "epoch 149 done at time 1305.2701985 \n",
      "epoch 150 done at time 1314.2933312 \n",
      "epoch 151 done at time 1323.1974143 \n",
      "epoch 152 done at time 1332.0850869 \n",
      "epoch 153 done at time 1341.4022819 \n",
      "epoch 154 done at time 1350.2663764 \n",
      "epoch 155 done at time 1359.0341467 \n",
      "epoch 156 done at time 1367.4178979 \n",
      "epoch 157 done at time 1375.7986784 \n",
      "epoch 158 done at time 1384.3311773 \n",
      "epoch 159 done at time 1392.749777 \n",
      "epoch 160 done at time 1401.4210778 \n",
      "epoch 161 done at time 1409.8782167 \n",
      "epoch 162 done at time 1418.5563852 \n",
      "epoch 163 done at time 1427.4973241 \n",
      "epoch 164 done at time 1436.1101486 \n",
      "epoch 165 done at time 1444.2755121 \n",
      "epoch 166 done at time 1453.1607653 \n",
      "epoch 167 done at time 1461.8379084 \n",
      "epoch 168 done at time 1470.6216627 \n",
      "epoch 169 done at time 1479.7670384 \n",
      "epoch 170 done at time 1488.0857824 \n",
      "epoch 171 done at time 1496.9078165 \n",
      "epoch 172 done at time 1506.0580261 \n",
      "epoch 173 done at time 1515.4193756 \n",
      "epoch 174 done at time 1524.2307308 \n",
      "epoch 175 done at time 1532.8573592 \n",
      "epoch 176 done at time 1541.243781 \n",
      "epoch 177 done at time 1549.9959953 \n",
      "epoch 178 done at time 1558.6544642 \n",
      "epoch 179 done at time 1567.9108505 \n",
      "epoch 180 done at time 1577.199572 \n",
      "epoch 181 done at time 1585.9673138 \n",
      "epoch 182 done at time 1594.9991055 \n",
      "epoch 183 done at time 1603.9171373 \n",
      "epoch 184 done at time 1613.2102499 \n",
      "epoch 185 done at time 1622.2558158 \n",
      "epoch 186 done at time 1630.9882181 \n",
      "epoch 187 done at time 1639.5898997 \n",
      "epoch 188 done at time 1648.3287016 \n",
      "epoch 189 done at time 1656.9295532 \n",
      "epoch 190 done at time 1665.9301966 \n",
      "epoch 191 done at time 1674.6380624 \n",
      "epoch 192 done at time 1683.4727957 \n",
      "epoch 193 done at time 1692.5692908 \n",
      "epoch 194 done at time 1701.4295404 \n",
      "epoch 195 done at time 1710.2621602 \n",
      "epoch 196 done at time 1718.7629414 \n",
      "epoch 197 done at time 1727.8917958 \n",
      "epoch 198 done at time 1736.9664011 \n",
      "epoch 199 done at time 1746.6299125 \n"
     ]
    }
   ],
   "source": [
    "input_dim = df.shape[1]-1\n",
    "output_dim = 5\n",
    "numofepochs = 200\n",
    "learningrate = 0.02\n",
    "\n",
    "model = ANN(Input_dim = input_dim,Output_dim = output_dim)\n",
    "trainAcc,testAcc,losses,model = trainthemodel(learningrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "\n",
    "\n",
    "ax[0].plot(losses,'k^-')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_title('Losses over epoch')\n",
    "\n",
    "ax[1].plot(trainAcc,)\n",
    "ax[1].plot(testAcc,)\n",
    "ax[1].set_title('Accuracy epochs')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].legend(['Train','Test'])\n",
    "ax[1].set_ylim([0,103])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.8560996055603"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the final accuracy, if using sample data, this should be around 25% as there is no structure to the data. \n",
    "\n",
    "# because its a small batch we can just run this on the CPU\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "100*torch.mean((torch.argmax(model(eval_data),axis=1) == eval_labels).float()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'../Deeplearningmodels/deeplearningapproach.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
