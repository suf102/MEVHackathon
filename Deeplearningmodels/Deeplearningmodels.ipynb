{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning library of choice PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for number-crunching\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datelets/datalet9.csv',index_col=False)\n",
    "df = df.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period0</th>\n",
       "      <th>period1</th>\n",
       "      <th>period2</th>\n",
       "      <th>period3</th>\n",
       "      <th>period4</th>\n",
       "      <th>period5</th>\n",
       "      <th>period6</th>\n",
       "      <th>period7</th>\n",
       "      <th>period8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         period0  period1  period2  period3  period4  period5  period6  \\\n",
       "0              3        2        0        2        1        1        0   \n",
       "1              2        0        2        1        1        0        1   \n",
       "2              0        2        1        1        0        1        3   \n",
       "3              2        1        1        0        1        3        2   \n",
       "4              1        1        0        1        3        2        3   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "9999995        2        0        3        2        2        0        1   \n",
       "9999996        0        3        2        2        0        1        2   \n",
       "9999997        3        2        2        0        1        2        3   \n",
       "9999998        2        2        0        1        2        3        4   \n",
       "9999999        2        0        1        2        3        4        5   \n",
       "\n",
       "         period7  period8  \n",
       "0              1        3  \n",
       "1              3        2  \n",
       "2              2        3  \n",
       "3              3        1  \n",
       "4              1        0  \n",
       "...          ...      ...  \n",
       "9999995        2        3  \n",
       "9999996        3        4  \n",
       "9999997        4        5  \n",
       "9999998        5        6  \n",
       "9999999        6        7  \n",
       "\n",
       "[10000000 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataheaders = []\n",
    "\n",
    "for i in range(df.shape[1]):\n",
    "\tdataheaders.append('period{}'.format(i))\n",
    "\t\n",
    "\n",
    "data = torch.Tensor(df[dataheaders].values).float()\n",
    "labels = torch.Tensor(df['period{}'.format(df.shape[1]-1)].values).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 2., 0.,  ..., 0., 1., 3.],\n",
      "        [2., 0., 2.,  ..., 1., 3., 2.],\n",
      "        [0., 2., 1.,  ..., 3., 2., 3.],\n",
      "        ...,\n",
      "        [3., 2., 2.,  ..., 3., 4., 5.],\n",
      "        [2., 2., 0.,  ..., 4., 5., 6.],\n",
      "        [2., 0., 1.,  ..., 5., 6., 7.]])\n",
      "tensor([3, 2, 3,  ..., 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to split the data into three parts, evaluation, test and training data. I do this with two instances of train_test_split, just for the sake of convinience.\n",
    "\n",
    "traintemp_data,eval_data, traintemp_labels,eval_labels = train_test_split(data, labels, test_size=.01)\n",
    "\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(traintemp_data, traintemp_labels, test_size=.01)\n",
    "\n",
    "#then we are going to pass the data to the Pytorch data loader, this is going to allow us to split it into mini batches that will be run through the model.\n",
    "#given that we are working with 10mil data points this is essential or we would simply run out of memory on the devices. Im using 2048 in the hope there are some gains to be made with that matrix size.\n",
    "\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "train_data = train_data\n",
    "test_data = test_data\n",
    "\n",
    "batchsize    = 2048\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model WITH BATCH NORM\n",
    "\n",
    "class ANN(nn.Module):\n",
    "\tdef __init__(self, Input_dim, Output_dim):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t### input layer\n",
    "\t\tself.input = nn.Linear(Input_dim,16)\n",
    "\t\t\n",
    "\t\t### hidden layers\n",
    "\t\tself.fc1    = nn.Linear(16,32)\n",
    "#    self.bnorm1 = nn.BatchNorm1d(16) \n",
    "\t\tself.fc2    = nn.Linear(32,32)\n",
    "#    self.bnorm2 = nn.BatchNorm1d(32) \n",
    "\t\tself.fc3    = nn.Linear(32,20)\n",
    "\t\t\n",
    "\t\t### output layer\n",
    "\t\tself.output = nn.Linear(20,Output_dim)\n",
    "\t\n",
    "\t# forward pass\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\t# input (x starts off normalized)\n",
    "\t\tx = F.relu( self.input(x) )\n",
    "\n",
    "\n",
    "\t\t# hidden layer 1\n",
    "#    x = self.bnorm1(x) # batchnorm\n",
    "\t\tx = F.relu( self.fc1(x) )      # linear function and activation function\n",
    "\n",
    "\t\t# hidden layer 2\n",
    "#    x = self.bnorm2(x) # batchnorm\n",
    "\t\tx = F.relu( self.fc2(x) )      # linear function and activation function\n",
    "\t\t\n",
    "\t\t# hidden layer 3\n",
    "\t\t\n",
    "\t\tx = F.relu( self.fc3(x) )      # linear function and activation function\n",
    "\n",
    "\t\t# output layer\n",
    "\t\treturn self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = df.shape[1]\n",
    "output_dim = 4\n",
    "numofepochs = 1000\n",
    "\n",
    "\n",
    "model = ANN(Input_dim = input_dim,Output_dim = output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainthemodel():\n",
    "\t\n",
    "\t# Loss function and optimizer, I chose the BCE loss function as it is best for classification problems. \n",
    "\tlossfun = nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\t\n",
    "\t#initialize losses\n",
    "\tlosses = torch.zeros(numofepochs)\n",
    "\ttrainAcc = []\n",
    "\ttestAcc = []\n",
    "\t\n",
    "\t#now lets actually loop over the training epochs to train the model\n",
    "\tfor epoch in range(numofepochs):\n",
    "\t\t\n",
    "\t\t# switch on training mode\n",
    "\t\tmodel.train()\n",
    "\n",
    "\t\t# loop over training data batches\n",
    "\t\tbatchAcc  = []\n",
    "\t\tbatchLoss = []\n",
    "\t\tfor X,y in train_loader:\n",
    "\t\t\t\n",
    "\t\t\t# forward pass and loss\n",
    "\t\t\tyHat = model(X)\n",
    "\t\t\tloss = lossfun(yHat,y)\n",
    "\n",
    "\t\t\t# backprop\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# loss from this batch\n",
    "\t\t\tbatchLoss.append(loss.item())\n",
    "\n",
    "\t\t\t# compute training accuracy for this batch\n",
    "\t\t\tbatchAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n",
    "\t\t\t\n",
    "\t\t# now that we've trained through the batches, get their average training accuracy\n",
    "\t\ttrainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "\t\t# and get average losses across the batches\n",
    "\t\tlosses[epoch] = np.mean(batchLoss)\n",
    "\t\t\n",
    "\t\t### test accuracy\n",
    "\n",
    "\t\t# NOTE: batch normalization should be turned off during testing, so we definitely need to switch modes here\n",
    "\t\tmodel.eval()\n",
    "\t\tX,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "\t\twith torch.no_grad(): # deactivates autograd\n",
    "\t\t\tyHat = model(X)\n",
    "\t\ttestAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )\n",
    "\t\t\n",
    "\t# function output\n",
    "\treturn trainAcc,testAcc,losses,model\n",
    "\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 6 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39172/3235204587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mANN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrainAcc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestAcc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainthemodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39172/951766619.py\u001b[0m in \u001b[0;36mtrainthemodel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m                         \u001b[1;31m# forward pass and loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                         \u001b[0myHat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myHat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         \u001b[1;31m# backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3014\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 6 is out of bounds."
     ]
    }
   ],
   "source": [
    "input_dim = df.shape[1]\n",
    "output_dim = 4\n",
    "numofepochs = 1000\n",
    "\n",
    "\n",
    "model = ANN(Input_dim = input_dim,Output_dim = output_dim)\n",
    "trainAcc,testAcc,losses,model = trainthemodel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
